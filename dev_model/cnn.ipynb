{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 109450 into shape (4975,5,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m     save_prediction_vs_actual_graph(y_test_split, y_pred, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction_vs_actual.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 78\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m X, y \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[1;32m     77\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Number of timesteps (days)\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m X_train, y_train, feature_scaler \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Split into training and test sets (80-20 split)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m split_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train))\n",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(X, y, timesteps)\u001b[0m\n\u001b[1;32m     31\u001b[0m feature_scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m     32\u001b[0m X_reshaped \u001b[38;5;241m=\u001b[39m feature_scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_reshaped\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X_reshaped\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m---> 33\u001b[0m X_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mX_reshaped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_reshaped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_reshaped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_reshaped, y_reshaped, feature_scaler\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 109450 into shape (4975,5,4)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data loading function (replace with your actual data)\n",
    "def load_data():\n",
    "    # For illustration, replace with your actual data loading logic\n",
    "    # Simulating data with 1000 samples, 22 features\n",
    "    X = np.random.rand(1000, 22)\n",
    "    y = np.random.rand(1000)\n",
    "    return X, y\n",
    "\n",
    "# Data preprocessing\n",
    "def preprocess_data(X, y, timesteps=5):\n",
    "    X_reshaped = []\n",
    "    y_reshaped = []\n",
    "    \n",
    "    # Create rolling window for timesteps\n",
    "    for i in range(timesteps, len(X)):\n",
    "        X_reshaped.append(X[i-timesteps:i])  # Use previous 'timesteps' for prediction\n",
    "        y_reshaped.append(y[i])  # Use next day as target\n",
    "    \n",
    "    X_reshaped = np.array(X_reshaped)\n",
    "    y_reshaped = np.array(y_reshaped)\n",
    "    \n",
    "    # Normalize the data\n",
    "    feature_scaler = StandardScaler()\n",
    "    X_reshaped = feature_scaler.fit_transform(X_reshaped.reshape(-1, X_reshaped.shape[2]))\n",
    "    X_reshaped = X_reshaped.reshape(X_reshaped.shape[0], timesteps, X_reshaped.shape[1] // timesteps)\n",
    "    \n",
    "    return X_reshaped, y_reshaped, feature_scaler\n",
    "\n",
    "# CNN model definition\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 2, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))  # Regression output\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Save training and validation loss graph\n",
    "def save_loss_graph(history, filename=\"loss_curve.png\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Save prediction vs actual graph\n",
    "def save_prediction_vs_actual_graph(y_true, y_pred, filename=\"prediction_vs_actual.png\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_true, y_pred, color='blue', alpha=0.5)\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='red', linestyle='--')\n",
    "    plt.title('Prediction vs Actual')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    X, y = load_data()\n",
    "    timesteps = 5  # Number of timesteps (days)\n",
    "    X_train, y_train, feature_scaler = preprocess_data(X, y, timesteps)\n",
    "    \n",
    "    # Split into training and test sets (80-20 split)\n",
    "    split_index = int(0.8 * len(X_train))\n",
    "    X_train_split, X_test_split = X_train[:split_index], X_train[split_index:]\n",
    "    y_train_split, y_test_split = y_train[:split_index], y_train[split_index:]\n",
    "    \n",
    "    # Create and train the CNN model\n",
    "    cnn_model = create_cnn_model(X_train_split.shape[1:])\n",
    "    history = cnn_model.fit(X_train_split, y_train_split, epochs=10, batch_size=32, validation_data=(X_test_split, y_test_split), verbose=1)\n",
    "    \n",
    "    # Save loss graph\n",
    "    save_loss_graph(history, \"training_loss_curve.png\")\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss = cnn_model.evaluate(X_test_split, y_test_split)\n",
    "    print(f\"Test loss: {test_loss}\")\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = cnn_model.predict(X_test_split)\n",
    "    print(f\"Predictions: {y_pred[:5]}\")  # Print first 5 predictions\n",
    "    \n",
    "    # Save prediction vs actual graph\n",
    "    save_prediction_vs_actual_graph(y_test_split, y_pred, \"prediction_vs_actual.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
